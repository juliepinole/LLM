{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliepinole/LLM/blob/main/Assignment2_q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUYEY7EVFGuY"
      },
      "source": [
        "# Prompting and Calibration\n",
        "\n",
        "Large Language Models (LLMs) excel at various tasks and it is interesting to understand when they can be trusted with their generations. **A first step towards making LLMs more trustworthy is to align their associated prediction confidence with their accuracy.**.\n",
        "\n",
        "That's where calibration comes in. A calibrated model will have the confidence level associated with its prediction aligned with the likelihood of the prediction being correct.\n",
        "\n",
        "\n",
        "There are several ways to make an LLM more calibrated with its predictions. Some of the more popular ideas are\n",
        "- Temperature scaling ([source](https://arxiv.org/pdf/1706.04599.pdf))\n",
        "- fine-tuning the model ([source](https://arxiv.org/pdf/2402.06544.pdf))\n",
        "- Post hoc estimation of the probability of its generated responses ([source](https://arxiv.org/abs/2207.05221))\n",
        "- Explanation-based prompting strategy with self-consistency ([source](https://arxiv.org/pdf/2402.13904.pdf))\n",
        "- and many others ...\n",
        "\n",
        "\n",
        "Due to limited resources, we will only explore the effect of different prompting strategies on the calibration properties of the model.\n",
        "\n",
        "Parts that require your interaction are marked TODO:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dkXBfXgM4wW"
      },
      "source": [
        "Before going into details, we start by installing some dependencies.\n",
        "We use the [vLLM](https://github.com/vllm-project/vllm) library for our experiments because of its efficient inference implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BIjqMBMANPgb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vllm\n",
            "  Using cached vllm-0.5.0.post1-cp310-cp310-manylinux1_x86_64.whl (130.2 MB)\n",
            "Collecting sentencepiece\n",
            "  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting fastapi\n",
            "  Using cached fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "Collecting uvicorn[standard]\n",
            "  Using cached uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "Collecting vllm-flash-attn==2.5.9\n",
            "  Using cached vllm_flash_attn-2.5.9-cp310-cp310-manylinux1_x86_64.whl (37.1 MB)\n",
            "Collecting torch==2.3.0\n",
            "  Using cached torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "Collecting filelock>=3.10.4\n",
            "  Using cached filelock-3.15.1-py3-none-any.whl (15 kB)\n",
            "Collecting prometheus-client>=0.18.0\n",
            "  Using cached prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
            "Requirement already satisfied: typing-extensions in /home/pinolej/.venv_3/lib/python3.10/site-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: psutil in /home/pinolej/.venv_3/lib/python3.10/site-packages (from vllm) (5.9.8)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m193.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting cmake>=3.21\n",
            "  Using cached cmake-3.29.5.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Collecting lm-format-enforcer==0.10.1\n",
            "  Using cached lm_format_enforcer-0.10.1-py3-none-any.whl (42 kB)\n",
            "Collecting tokenizers>=0.19.1\n",
            "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Collecting pillow\n",
            "  Using cached pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Collecting transformers>=4.40.0\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken>=0.6.0\n",
            "  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting ninja\n",
            "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "Collecting py-cpuinfo\n",
            "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting xformers==0.0.26.post1\n",
            "  Using cached xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
            "Collecting openai\n",
            "  Using cached openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0\n",
            "  Using cached prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting ray>=2.9\n",
            "  Using cached ray-2.24.0-cp310-cp310-manylinux2014_x86_64.whl (65.9 MB)\n",
            "Collecting outlines>=0.0.43\n",
            "  Using cached outlines-0.0.45-py3-none-any.whl (101 kB)\n",
            "Collecting pydantic>=2.0\n",
            "  Using cached pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
            "Collecting nvidia-ml-py\n",
            "  Using cached nvidia_ml_py-12.555.43-py3-none-any.whl (39 kB)\n",
            "Collecting aiohttp\n",
            "  Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting pyyaml\n",
            "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "Collecting interegular>=0.3.2\n",
            "  Using cached interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging in /home/pinolej/.venv_3/lib/python3.10/site-packages (from lm-format-enforcer==0.10.1->vllm) (24.1)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting jinja2\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.3.0\n",
            "  Using cached triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "Collecting numba\n",
            "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting pyairports\n",
            "  Using cached pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Collecting referencing\n",
            "  Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting pycountry\n",
            "  Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "Collecting diskcache\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Collecting lark\n",
            "  Using cached lark-1.1.9-py3-none-any.whl (111 kB)\n",
            "Collecting jsonschema\n",
            "  Using cached jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
            "Requirement already satisfied: nest-asyncio in /home/pinolej/.venv_3/lib/python3.10/site-packages (from outlines>=0.0.43->vllm) (1.6.0)\n",
            "Collecting cloudpickle\n",
            "  Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
            "Collecting starlette<1.0.0,>=0.30.0\n",
            "  Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "Collecting pydantic-core==2.18.4\n",
            "  Using cached pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Collecting annotated-types>=0.4.0\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting msgpack<2.0.0,>=1.0.0\n",
            "  Using cached msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
            "Collecting click>=7.0\n",
            "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Collecting frozenlist\n",
            "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "Collecting aiosignal\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3\n",
            "  Downloading protobuf-5.27.1-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting regex>=2022.1.18\n",
            "  Using cached regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4\n",
            "  Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.4.1\n",
            "  Using cached safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "Collecting async-timeout<5.0,>=4.0\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting httpx>=0.23.0\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Collecting python-multipart>=0.0.7\n",
            "  Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting fastapi-cli>=0.0.2\n",
            "  Using cached fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1\n",
            "  Using cached ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "Collecting orjson>=3.2.1\n",
            "  Using cached orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "Collecting email_validator>=2.0.0\n",
            "  Using cached email_validator-2.1.2-py3-none-any.whl (30 kB)\n",
            "Collecting h11>=0.8\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting httptools>=0.5.0\n",
            "  Using cached httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "Collecting python-dotenv>=0.13\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
            "  Using cached uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "Collecting watchfiles>=0.13\n",
            "  Using cached watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting websockets>=10.4\n",
            "  Using cached websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "Collecting anyio<5,>=3.5.0\n",
            "  Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
            "Collecting sniffio\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting distro<2,>=1.7.0\n",
            "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/pinolej/.venv_3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->vllm) (1.2.1)\n",
            "Collecting dnspython>=2.0.0\n",
            "  Using cached dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "Collecting typer>=0.12.3\n",
            "  Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "Collecting httpcore==1.*\n",
            "  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting multiprocess\n",
            "  Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Collecting xxhash\n",
            "  Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Collecting pyarrow-hotfix\n",
            "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0\n",
            "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Collecting fsspec[http]<=2024.5.0,>=2023.1.0\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=15.0.0\n",
            "  Using cached pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "Collecting rpds-py>=0.7.1\n",
            "  Using cached rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting jsonschema-specifications>=2023.03.6\n",
            "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0\n",
            "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting mpmath<1.4.0,>=1.1.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting rich>=10.11.0\n",
            "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "Collecting shellingham>=1.3.0\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting tzdata>=2022.7\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pinolej/.venv_3/lib/python3.10/site-packages (from pandas->datasets->outlines>=0.0.43->vllm) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /home/pinolej/.venv_3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines>=0.0.43->vllm) (1.16.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/pinolej/.venv_3/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (2.18.0)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: sentencepiece, pytz, pyairports, py-cpuinfo, nvidia-ml-py, ninja, mpmath, xxhash, websockets, uvloop, urllib3, ujson, tzdata, tqdm, sympy, sniffio, shellingham, safetensors, rpds-py, regex, pyyaml, python-multipart, python-dotenv, pydantic-core, pycountry, pyarrow-hotfix, protobuf, prometheus-client, pillow, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, msgpack, mdurl, MarkupSafe, llvmlite, lark, interegular, idna, httptools, h11, fsspec, frozenlist, filelock, dnspython, distro, diskcache, dill, cmake, cloudpickle, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, yarl, uvicorn, triton, requests, referencing, pydantic, pyarrow, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, multiprocess, markdown-it-py, jinja2, httpcore, email_validator, anyio, aiosignal, watchfiles, tiktoken, starlette, rich, nvidia-cusolver-cu12, lm-format-enforcer, jsonschema-specifications, huggingface-hub, httpx, aiohttp, typer, torch, tokenizers, prometheus-fastapi-instrumentator, openai, jsonschema, xformers, vllm-flash-attn, transformers, ray, fastapi-cli, datasets, outlines, fastapi, vllm\n",
            "Successfully installed MarkupSafe-2.1.5 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.4.0 async-timeout-4.0.3 attrs-23.2.0 certifi-2024.6.2 charset-normalizer-3.3.2 click-8.1.7 cloudpickle-3.0.0 cmake-3.29.5.1 datasets-2.20.0 dill-0.3.8 diskcache-5.6.3 distro-1.9.0 dnspython-2.6.1 email_validator-2.1.2 fastapi-0.111.0 fastapi-cli-0.0.4 filelock-3.15.1 frozenlist-1.4.1 fsspec-2024.5.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.4 idna-3.7 interegular-0.3.3 jinja2-3.1.4 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 lark-1.1.9 llvmlite-0.43.0 lm-format-enforcer-0.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.0.8 multidict-6.0.5 multiprocess-0.70.16 networkx-3.3 ninja-1.11.1.1 numba-0.60.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.555.43 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-1.34.0 orjson-3.10.5 outlines-0.0.45 pandas-2.2.2 pillow-10.3.0 prometheus-client-0.20.0 prometheus-fastapi-instrumentator-7.0.0 protobuf-5.27.1 py-cpuinfo-9.0.0 pyairports-2.1.1 pyarrow-16.1.0 pyarrow-hotfix-0.6 pycountry-24.6.1 pydantic-2.7.4 pydantic-core-2.18.4 python-dotenv-1.0.1 python-multipart-0.0.9 pytz-2024.1 pyyaml-6.0.1 ray-2.24.0 referencing-0.35.1 regex-2024.5.15 requests-2.32.3 rich-13.7.1 rpds-py-0.18.1 safetensors-0.4.3 sentencepiece-0.2.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.37.2 sympy-1.12.1 tiktoken-0.7.0 tokenizers-0.19.1 torch-2.3.0 tqdm-4.66.4 transformers-4.41.2 triton-2.3.0 typer-0.12.3 tzdata-2024.1 ujson-5.10.0 urllib3-2.2.2 uvicorn-0.30.1 uvloop-0.19.0 vllm-0.5.0.post1 vllm-flash-attn-2.5.9 watchfiles-0.22.0 websockets-12.0 xformers-0.0.26.post1 xxhash-3.4.1 yarl-1.9.4\n"
          ]
        }
      ],
      "source": [
        "# install dependencies (We are using VLLM to load our model and then to do inference over it)\n",
        "!pip install vllm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm7qon7TOB03"
      },
      "source": [
        "Once the dependency is installed, the next few important parameters to keep in mind are:\n",
        "- *SamplingParams* - to define the number of samples, temperature, maximum number of tokens, and to get the log probabilities.\n",
        "- *LLM* - for initializing the model given it's name\n",
        "- *llm.generate* - to generate the output\n",
        "\n",
        "If interested in more details, prefer refer to the [vLLM documentation](https://docs.vllm.ai/en/latest/getting_started/quickstart.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PhzXB4wSy4C6"
      },
      "outputs": [],
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "import math\n",
        "import random\n",
        "from typing import List, Any\n",
        "\n",
        "random.seed(42)\n",
        "!export VLLM_USE_MODELSCOPE=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wF_kDwCQx5h-"
      },
      "outputs": [],
      "source": [
        "def initialize_model(model_name: str):\n",
        "  llm = LLM(model=model_name, trust_remote_code=True)\n",
        "  print(f\"{model_name} initialized successfully!!\")\n",
        "  return llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E95xLa48x7C9"
      },
      "outputs": [],
      "source": [
        "def generate(llm, prompt: str, num_samples: int, temperature: float):\n",
        "  \"\"\"\n",
        "  Generate completions from the LLM.\n",
        "  :param llm: Model instance.\n",
        "  :param prompt: Text of the prompt.\n",
        "  :param num_samples: Number of samples to generate.\n",
        "  :param temperature: Temperature for sampling.\n",
        "  :return: List of generated texts, List of the raw outputs\n",
        "  \"\"\"\n",
        "  sampling_params = SamplingParams(temperature=temperature, n=num_samples, max_tokens=500, logprobs=1, seed=42)\n",
        "  outputs = llm.generate([prompt], sampling_params)\n",
        "  completions = [output.text for output in outputs[0].outputs]\n",
        "  return completions, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rkJZL_vRzevm"
      },
      "outputs": [],
      "source": [
        "# Example prompt -> Just to test the model\n",
        "prompt = \"what is the meaning of life?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2ObfkfWz_kZF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 06-18 16:12:40 config.py:437] Possibly too large swap space. 4.00 GiB out of the 7.60 GiB total CPU memory is allocated for the swap space.\n",
            "INFO 06-18 16:12:40 llm_engine.py:161] Initializing an LLM engine (v0.5.0.post1) with config: model='microsoft/phi-2', speculative_config=None, tokenizer='microsoft/phi-2', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=microsoft/phi-2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pinolej/.venv_3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 06-18 16:12:41 utils.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#load the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/phi-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/entrypoints/llm.py:144\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, enforce_eager, max_context_len_to_capture, max_seq_len_to_capture, disable_custom_all_reduce, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    124\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    125\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    126\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    143\u001b[0m )\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/engine/llm_engine.py:363\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context)\u001b[0m\n\u001b[1;32m    360\u001b[0m     executor_class \u001b[38;5;241m=\u001b[39m GPUExecutor\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/engine/llm_engine.py:223\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, vision_language_config, speculative_config, decoding_config, executor_class, log_stats, usage_context)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_counter \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config_fields \u001b[38;5;241m=\u001b[39m _load_generation_config_dict(\n\u001b[1;32m    221\u001b[0m     model_config)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvision_language_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeculative_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeculative_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39membedding_mode:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_kv_caches()\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/executor/executor_base.py:41\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, vision_language_config, speculative_config)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_language_config \u001b[38;5;241m=\u001b[39m vision_language_config\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeculative_config \u001b[38;5;241m=\u001b[39m speculative_config\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:22\u001b[0m, in \u001b[0;36mGPUExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the worker and load the model.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPUExecutor only supports single GPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker\u001b[38;5;241m.\u001b[39minit_device()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker\u001b[38;5;241m.\u001b[39mload_model()\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:67\u001b[0m, in \u001b[0;36mGPUExecutor._create_worker\u001b[0;34m(self, local_rank, rank, distributed_init_method)\u001b[0m\n\u001b[1;32m     61\u001b[0m     worker_class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_spec_worker\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m WorkerWrapperBase(\n\u001b[1;32m     64\u001b[0m     worker_module_name\u001b[38;5;241m=\u001b[39mworker_module_name,\n\u001b[1;32m     65\u001b[0m     worker_class_name\u001b[38;5;241m=\u001b[39mworker_class_name,\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_worker_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mdistributed_init_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\u001b[38;5;241m.\u001b[39mworker\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/worker/worker_base.py:134\u001b[0m, in \u001b[0;36mWorkerWrapperBase.init_worker\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m mod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_module_name)\n\u001b[1;32m    133\u001b[0m worker_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_class_name)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker \u001b[38;5;241m=\u001b[39m \u001b[43mworker_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/worker/worker.py:75\u001b[0m, in \u001b[0;36mWorker.__init__\u001b[0;34m(self, model_config, parallel_config, scheduler_config, device_config, cache_config, load_config, local_rank, rank, distributed_init_method, lora_config, vision_language_config, speculative_config, is_driver_worker)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_config, (\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo be tested: vision language model with LoRA settings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m ModelRunnerClass \u001b[38;5;241m=\u001b[39m (EmbeddingModelRunner \u001b[38;5;28;01mif\u001b[39;00m\n\u001b[1;32m     74\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39membedding_mode \u001b[38;5;28;01melse\u001b[39;00m ModelRunner)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_runner \u001b[38;5;241m=\u001b[39m \u001b[43mModelRunnerClass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_cache_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_driver_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_driver_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvision_language_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Uninitialized cache engine. Will be initialized by\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# initialize_cache.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_engine: CacheEngine\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/worker/model_runner.py:119\u001b[0m, in \u001b[0;36mModelRunner.__init__\u001b[0;34m(self, model_config, parallel_config, scheduler_config, device_config, cache_config, load_config, lora_config, kv_cache_dtype, is_driver_worker, vision_language_config)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# When using CUDA graph, the input block tables must be padded to\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# max_seq_len_to_capture. However, creating the block table in\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Python can be expensive. To optimize this, we cache the block table\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# in numpy and only copy the actual input content at every iteration.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# The shape of the cached block table will be\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# (max batch size to capture, max context len to capture / block size).\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_block_tables \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    117\u001b[0m     (\u001b[38;5;28mmax\u001b[39m(_BATCH_SIZES_TO_CAPTURE), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_max_block_per_batch()),\n\u001b[1;32m    118\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_backend \u001b[38;5;241m=\u001b[39m \u001b[43mget_attn_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_attention_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_head_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_kv_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sliding_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Create processor for multi-modal data\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_language_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/attention/selector.py:43\u001b[0m, in \u001b[0;36mget_attn_backend\u001b[0;34m(num_heads, head_size, num_kv_heads, sliding_window, dtype, kv_cache_dtype, block_size, is_blocksparse)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocksparse_attn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     40\u001b[0m         BlocksparseFlashAttentionBackend)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BlocksparseFlashAttentionBackend\n\u001b[0;32m---> 43\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mwhich_attn_to_use\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_kv_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m _Backend\u001b[38;5;241m.\u001b[39mFLASH_ATTN:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     48\u001b[0m         FlashAttentionBackend)\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/vllm/attention/selector.py:129\u001b[0m, in \u001b[0;36mwhich_attn_to_use\u001b[0;34m(num_heads, head_size, num_kv_heads, sliding_window, dtype, kv_cache_dtype, block_size)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# FlashAttn in NVIDIA GPUs.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_backend \u001b[38;5;241m==\u001b[39m _Backend\u001b[38;5;241m.\u001b[39mFLASH_ATTN:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_capability\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m8\u001b[39m:\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;66;03m# Volta and Turing NVIDIA GPUs.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use FlashAttention-2 backend for Volta and Turing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPUs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m         selected_backend \u001b[38;5;241m=\u001b[39m _Backend\u001b[38;5;241m.\u001b[39mXFORMERS\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/torch/cuda/__init__.py:430\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_capability\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m        tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     prop \u001b[38;5;241m=\u001b[39m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prop\u001b[38;5;241m.\u001b[39mmajor, prop\u001b[38;5;241m.\u001b[39mminor\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/torch/cuda/__init__.py:444\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
            "File \u001b[0;32m~/.venv_3/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        " #load the model\n",
        "llm = LLM(model=\"microsoft/phi-2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5Z0NB250MWr",
        "outputId": "6e758200-f49f-4c61-a838-7da7b7597c6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n\\nAnswer: The meaning of life is a philosophical question that has been debated for centuries. Some people believe that the meaning of life is to find happiness and fulfillment, while others believe that it is to serve a higher purpose or to make a positive impact on the world.\\n\\nExercise 2: What is the difference between ethics and morals?\\n\\nAnswer: Ethics are a set of principles that guide behavior, while morals are personal beliefs about what is right and wrong.\\n\\nExercise 3: What is the importance of ethics in the workplace?\\n\\nAnswer: Ethics are important in the workplace because they help to ensure that employees are treated fairly and that the company operates in a responsible and ethical manner.\\n\\nExercise 4: What is the importance of ethics in healthcare?\\n\\nAnswer: Ethics are important in healthcare because they help to ensure that patients are treated with respect and dignity, and that their rights are protected.\\n\\nExercise 5: What is the importance of ethics in the legal system?\\n\\nAnswer: Ethics are important in the legal system because they help to ensure that justice is served and that the rights of all individuals are protected.\\n']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# test the model generation\n",
        "generated_output, outputs = generate(llm, prompt, num_samples=1, temperature=0)\n",
        "print (generated_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY9dMAFpFXIa"
      },
      "source": [
        "The output of the model above consists of the generated text and associated logits.\n",
        "\n",
        "### Understanding Logits, Log Probabilities, and Their Relationship to Confidence Estimation\n",
        "**Logits are the raw outputs of the neural network layers before any normalization or activation function is applied. In the context of a language model, these are typically the outputs of the last linear layer, which predicts the next word or token in a sequence. These values can be positive, negative, or zero, representing the unnormalized scores for each possible next token.\n",
        "\n",
        "**Log probabilities** are the logarithm of the probabilities produced by the model after applying the softmax function to the logits (softmax exponentiates each logit (to ensure positivity) and then normalizes these values so that they sum to 1, making them valid probabilities).\n",
        "\n",
        "The log probabilities of the LLM generation can be used to estimate the confidence in its prediction ([source](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00407/107277/How-Can-We-Know-When-Language-Models-Know-On-the)). However, the log probabilities for an LLM output are generated for each token.\n",
        "\n",
        "To compute the confidence of the entire output, we can compute the **average of the logprob** for the output (sum of each token's logprob divided by its length) and then exponentiate it.\n",
        "This will give us the confidence associated with the entire output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF_kxfliGskV"
      },
      "source": [
        "# Question 1:\n",
        "\n",
        "For the above generated output, write a function to calculate the average probabilities of a given output sentence by using the definition from above. Fill the *calculate_average_logprobs* function below.\n",
        "\n",
        "Hint: Please review the [RequestOutput](https://github.com/vllm-project/vllm/blob/main/vllm/outputs.py#L60) variables, specificallu `prompt_logprobs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BfwEksFFpmh"
      },
      "outputs": [],
      "source": [
        "from vllm.outputs import RequestOutput\n",
        "\n",
        "def calculate_average_logprobs (input_sample: List[RequestOutput]) -> float:\n",
        "  \"\"\"\n",
        "  Calculate average logprobs for a list of RequestOutput instances.\n",
        "  :param input_sample: RequestOutput instance.\n",
        "  :return: Value of average logprobs.\n",
        "  \"\"\"\n",
        "  # TODO: write code here to calculate average logprobs\n",
        "  average_logprobs = [0]\n",
        "  return average_logprobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c99idK97Usm"
      },
      "outputs": [],
      "source": [
        "# Make sure this check passes to verify your answer.\n",
        "# comments here: Just check if it is 0.73.. and that should be ok too.\n",
        "calculate_average_logprobs(outputs) == [0.7392954323778061]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbCQbRHZGk57"
      },
      "source": [
        "Since one example works end to end, it is time to load GSM8K dataset of math word problem from huggingface and start experiments on that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAehyYPmSCUv"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGuUD0g12_fH"
      },
      "outputs": [],
      "source": [
        "# import datasets and load GSM8k dataset\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29BKNrq6EwSF"
      },
      "outputs": [],
      "source": [
        "def create_test_set():\n",
        "  dataset = load_dataset(\"gsm8k\", \"main\")\n",
        "  test_set = [dataset[\"test\"][i] for i in range(200)]\n",
        "  print (f\"A sample set of {len(test_set)} is created!\")\n",
        "  return test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "a4da2b93fb964890bd8c60b5589be2b4",
            "e5e3d39313ef428fa19f9aa8a156a77b",
            "eb68c89733bc469b886374c0b2095bb6",
            "0d0e11b9d72443d2bf9def227ed2ea63",
            "a2fa7fcda19f44729d1915e5cf218073",
            "02c816c5001049d49205088e6038913d",
            "54d57e78ff8b463199c60f153941ec76",
            "f4119fbb2ce0418db954e8c4a0f9cf98",
            "f9bf4c0504294ba198f3a14fad39cde1",
            "1f0a5e9e57b2466295b7cb1c7a26b0fe",
            "a824806e99f4452eb70c34d3c9b6e611",
            "742dc98251b64833895aedfb0a75dc57",
            "2288d8d0e58d438ea4e69a941469a20e",
            "c2f26a48ceb847fe8a2c5b0033d79c95",
            "772fc183e47746c4b588f0db80dfbf2f",
            "d630ea51a26941a99e6600719f3d425f",
            "ade627615fc745f6852649b91f06731d",
            "6fe8e8e3e86f466a889320d0f081bcb0",
            "126d1790bcea40478871169940597201",
            "dc62eb5beabb41bba0f34f431125eb05",
            "2c4c1c69632547e58cdb679a56ea2ef2",
            "c0b2ae5d6a9f4a43b64039f2476ec9ca",
            "572a5aa78add43448dabd41c632bdb9d",
            "7f06e4940c5848c9abca165ebad783b1",
            "a3f0b5b8b00448a68dd6a3082ad3853f",
            "78ef66e03f114444b41996516e1ed965",
            "634565d5d7ad42d1aeef4312adcd3cf0",
            "f820abda66f3408094e7c76d49f5af36",
            "f495c8b95c1b4c2e966917fb73891916",
            "0e038056823240b9835e3d8bdec7ea1d",
            "9e52cb5138534c9195bcc3e5b3a44b76",
            "200486cf53214f7ea528a5e8718da8a3",
            "d14e849a162441d4b617b6cfea8f22fb",
            "56ad38b691014c899b1227d6563be570",
            "bc2f3c24d0da489ca8652ecac12ab2b7",
            "6ae4fda98c6b41fa9f73c3d223f32b3c",
            "93b41ab10b1749daaab08d569ae37832",
            "0248df9db9534a7a98d49e11fcb24ce0",
            "c1dea8db8b2e4b38ab0af8a8f8a98653",
            "f345ad3e23564e91a5dbf3b048cb13d5",
            "aa0edf7a372b475bbb2302f0b6571b75",
            "181fdf8a346a490aa6eabbdb0907ef58",
            "f01676a335c04e47a589b15276d24912",
            "ba9555f939c84ebdbfe46b2ce2e503b5",
            "2c6be99ad92e41deba2545c41a5346c1",
            "62b9245851b141f79a66281ac9da797b",
            "e2ff941fab2f4e369b2977c87636fbc1",
            "f712424d53004d8b9af4f0b839bab24e",
            "29eaa09b31e34fa19f90f1c578a7cd47",
            "9422686d4ea340d2b68731e077785348",
            "028bb0fbfdc140dc87d103a438be30d8",
            "e20b6f66359d46218a6e7b9c41c0f4e9",
            "4a259eec653f48288266799298319b9a",
            "e13c992fb9944c6ea599d2002e1610ad",
            "945fc7b512a04a5c8384c325cc1dbe94"
          ]
        },
        "id": "AbXTqLcYM5Np",
        "outputId": "74e8a506-e321-43c5-b68f-567feede84fd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4da2b93fb964890bd8c60b5589be2b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "742dc98251b64833895aedfb0a75dc57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "572a5aa78add43448dabd41c632bdb9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56ad38b691014c899b1227d6563be570",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c6be99ad92e41deba2545c41a5346c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A sample set of 200 is created!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",\n",
              " 'answer': 'Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\\n#### 18'}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set = create_test_set()\n",
        "test_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhuop9tGFHK8",
        "outputId": "f424cdcc-bb4c-4e7f-a6cf-0673bdbfbffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A sample set of 200 is created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"\\n\\nSolution:\\nTo find out how much Janet makes every day at the farmers' market, we need to calculate the number of eggs she sells and multiply it by the price per egg.\\n\\nFirst, let's calculate the number of eggs Janet eats and bakes each day:\\nEggs eaten for breakfast = 3\\nEggs used for baking muffins = 4\\n\\nTotal eggs used = Eggs eaten for breakfast + Eggs used for baking muffins\\nTotal eggs used = 3 + 4 = 7\\n\\nNow, let's calculate the number of eggs Janet sells each day:\\nTotal eggs laid by Janet's ducks = 16\\nTotal eggs used = 7\\n\\nEggs sold at the farmers' market = Total eggs laid by Janet's ducks - Total eggs used\\nEggs sold at the farmers' market = 16 - 7 = 9\\n\\nFinally, let's calculate the amount Janet makes every day at the farmers' market:\\nPrice per fresh duck egg = $2\\nEggs sold at the farmers' market = 9\\n\\nAmount made at the farmers' market = Price per fresh duck egg * Eggs sold at the farmers' market\\nAmount made at the farmers' market = $2 * 9 = $18\\n\\nTherefore, Janet makes $18 every day at the farmers' market.\\n\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_set = create_test_set()\n",
        "\n",
        "# Testing the model on one example\n",
        "test_sample1_output, output_everything = generate(llm, prompt=test_set[0][\"question\"], num_samples=1, temperature=0)\n",
        "print(test_sample1_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6tj3T96IpgJ"
      },
      "source": [
        "Now that we have the setup to generate solutions and get their log probability based confidence, we can look at how to feed the input into the model.\n",
        "\n",
        "# Prompting\n",
        "\n",
        "**Prompting is a method of interacting with (LLMs) by providing them with text input (the prompt) that instructs or guides the model on what kind of output is desired. Because LLMs are trained on a large amount of data, they are biased to generate their response in a certain way. Prompting can override this bias and allow LLMs to follow a particular style.\n",
        "\n",
        "For our task, we are interested in exploring the following styles of prompting:\n",
        "\n",
        "1. **Answer Only**: The most naive strategy, where a question along with an instruction is accompanied only by an answer. No explanation of why or how the model arrived at the final answer is required.\n",
        "2. **Chain-of-Thought Prompting**: A prompting technique that encourages the model to generate intermediate steps or reasoning paths as it generates its response. ([Paper](https://arxiv.org/abs/2201.11903))\n",
        "3. **Subquestion Decomposition**: This technique allows the question to be broken down into simpler questions, and then each of those questions answered to arrive at the final answer. ([Paper](https://arxiv.org/abs/2205.10625))\n",
        "\n",
        "\n",
        "## Zero-shot vs. few-shot setting\n",
        "\n",
        "Zero-shot and few-shot prompting are terms used to describe how language models can perform a given task based on the demonstrations provided to them.\n",
        "\n",
        "1. **Zero-shot: Zero-shot prompting involves presenting a task to a language model without providing examples of how to complete it. However, zero-shot prompting may include instructions on how to complete the task.\n",
        "2. **Few-shot prompting: Few-shot prompting involves providing a small number of examples within the prompt to illustrate how the task should be performed. These examples serve as a guide to help the model understand the format, style, or type of information that's expected in the response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqLQ-WwfR3R6"
      },
      "source": [
        "# Question 2\n",
        "Based on the three prompting strategies defined above (answer only, chain of thought, and subquestion decomposition), generate the outputs for the test set in:\n",
        "\n",
        "1. in zero-shot setting\n",
        "2. in four-shot setting (few-shot with four examples shown)\n",
        "\n",
        "and, report the accuracy for the two settings for each prompting strategy.\n",
        "\n",
        "\n",
        "Note: calculate the accuracy by taking the last number in the generation and comparing it with the final answer in the dataset (after ####). For all the generations, use greedy decoding (temp = 0) with 1 sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRGCHxsRYPL5"
      },
      "outputs": [],
      "source": [
        "def accuracy(generation: str, gt_answer: str) -> float:\n",
        "  \"\"\"\n",
        "  Calculate exact match accuracy between generation and ground truth answer.\n",
        "  :param generation: Generated answer.\n",
        "  :param gt_answer: Ground truth answer from GSM8k.\n",
        "  :return: 1 if exact match, zero if not.\n",
        "  \"\"\"\n",
        "  # TODO: extract final answer from generation (complete get_pred function below)\n",
        "  # hint: extract final answer from gt which is delimited by ####\n",
        "\n",
        "  #compare the two and return the accuracy in binary 1. or 0.\n",
        "  acc = 0\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkQMmmtkTr6B"
      },
      "outputs": [],
      "source": [
        "# TODO: complete the prediction function below\n",
        "import re\n",
        "def get_pred(sample: str) -> float:\n",
        "  \"\"\"\n",
        "  Return the last number from the prediction\n",
        "  :param sample: Generated answer.\n",
        "  :return: last number in the generated answer.\n",
        "  \"\"\"\n",
        "  # hint: useful regex: r'[$]?[-+]?\\d+(?:\\.\\d+)?(?:,\\d+)*[$]?'\n",
        "  pred_val = 0\n",
        "  return pred_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t6JzC7CMDhA"
      },
      "outputs": [],
      "source": [
        "# TODO: complete the prompt examples below for zero-shot setting\n",
        "\n",
        "answer_only_prompt = \"\"\n",
        "cot_prompt = \"\"\n",
        "subques_prompt = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL2yhjlrOPCC"
      },
      "outputs": [],
      "source": [
        "# TODO: complete the prompt examples below for four-shot setting\n",
        "\n",
        "answer_only_prompt = \"\"\n",
        "cot_prompt = \"\"\n",
        "subques_prompt = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9PzHtR7OFVD"
      },
      "outputs": [],
      "source": [
        "# TODO: calculate accuracy on test set\n",
        "def calculate_accuracy(prompt_style: str):\n",
        "  acc_list, conf_list = [], []\n",
        "  for test_sample in test_set:\n",
        "    input_to_llm = prompt_style + test_sample[\"question\"]\n",
        "    test_sample_output, everything_else = generate(llm, input_to_llm, 1, 0)\n",
        "    gt_answer = test_sample[\"answer\"]\n",
        "\n",
        "    # calculate accuracy between test_sample_output and gt_answer\n",
        "    acc = accuracy(test_sample_output, gt_answer)\n",
        "    acc_list.append(acc)\n",
        "    conf = 0 # call confidence estimation function from ques 1\n",
        "    conf_list.append(conf)\n",
        "  print (f\"Final accuracy : {sum(acc_list) / len(test_set)}\")\n",
        "\n",
        "  return acc_list, conf_list\n",
        "\n",
        "acc_list, conf_list = calculate_accuracy(prompt_style = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8fLjSLcObi9"
      },
      "source": [
        "#### Can approaches with equal accuracy be trusted equally?\n",
        "\n",
        "The answer is No. A simple intuition behind this is that we want a model that places high confidence in the correct outputs and low confidence in the incorrect ones. This allows us to place more trust in the high confidence samples during testing when correct labels are unknown.\n",
        "\n",
        "This is where **calibration** comes in handy.\n",
        "\n",
        "# Calibration\n",
        "\n",
        "\n",
        "Calibration in the context of LLMs refers to the process of adjusting the model's outputs to ensure that its confidence levels accurately reflect the true likelihood of those outputs being correct. When a model is well-calibrated, its predicted probabilities of outcomes should match the observed outcomes. For example, if an LLM predicts a certain answer to a question with 80% confidence, then, ideally, 80% of the answers predicted with that confidence level should be correct.\n",
        "\n",
        "\n",
        "### How to measure calibration in LLMs?\n",
        "\n",
        "The Expected Calibration Error (ECE) score is a metric used to evaluate the calibration of probabilistic models, including LLMs. It measures the difference between the model's predicted probabilities and the actual outcomes, providing a quantitative assessment of how well the model's confidence levels match its accuracy.\n",
        "\n",
        "### How ECE is calculated\n",
        "The ECE score is calculated by grouping the model's predictions into bins based on their confidence levels. For each bin:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   **Compute the average confidence**: Calculate the mean predicted confidence of the predictions in the bin.\n",
        "2.   **Compute the accuracy**: Calculate the fraction of correct predictions in the bin.\n",
        "3.   **Compute the absolute difference**: Find the absolute difference between the average confidence and the accuracy for the bin.\n",
        "\n",
        "The ECE score is then the weighted average of these differences across all bins, where the weights are proportional to the number of predictions in each bin. The formula for ECE can be summarized as follows:\n",
        "\n",
        "\n",
        "$\n",
        "\\text{ECE} = \\sum_{i=1}^{N} \\frac{|B_i|}{n} \\left| \\text{acc}(B_i) - \\text{conf}(B_i) \\right|\\ $\n",
        "\n",
        "where,\n",
        "\n",
        "$N$ represents the number of bins into which the predictions are grouped based on their confidence level.\n",
        "\n",
        "$B_i$ denotes the set of predictions in the $i^{th}$ bin.\n",
        "\n",
        "$|B_i|$ is the number of predictions in bin $i$.\n",
        "\n",
        "$n$ is the total number of predictions across all bins.\n",
        "\n",
        "$\\text{acc}(B_i)$ is the accuracy within bin $i$, calculated as the proportion of correct predictions.\n",
        "\n",
        "conf$(B_i)$ is the average confidence level of the predictions in bin $i$.\n",
        "\n",
        "The sum across all bins of the product of the proportion of predictions in each bin and the absolute difference between the average confidence and accuracy in that bin gives the ECE score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQT_Ttk2Yo-t"
      },
      "source": [
        "\n",
        "A good way to plot a model's calibration is to use Reliability diagram.\n",
        "# Reliability Diagram\n",
        "\n",
        "A reliability diagram plots the model's confidence levels on the x-axis against the actual accuracy of predictions at those confidence levels on the y-axis. Confidence levels are typically binned into intervals (e.g., 0-10%, 10-20%, ..., 90-100%), and for each bin, the mean predicted confidence is plotted against the observed accuracy of predictions falling into that bin.\n",
        "\n",
        "## Interpreting a Reliability Diagram\n",
        "* **Below the Line**: If the data points for a bin are below the diagonal line, the model is overconfident; its actual accuracy is lower than its predicted confidence.\n",
        "* **Above the Line**: If the data points for a bin are above the diagonal line, the model is underconfident; its actual accuracy is higher than its predicted confidence.\n",
        "* **On the Line**: Data points on the diagonal line indicate perfect calibration; the model's predicted confidence matches its empirical accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd89rRj-Y8Kb"
      },
      "source": [
        "# Question 3:\n",
        "\n",
        "For each of the generated samples with different prompting strategies in Question 2, calculate the ECE score for all of them.\n",
        "\n",
        "\n",
        "1.   Report the ECE score for all strategies and provide your reasoning behind why one prompting strategy is more calibrated than the other.\n",
        "2.   Plot the reliability diagram for all of the above cases with bin size of 10.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t58JTGltUTVS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_ece(acc_list: List[float], conf_list: List[float]) -> float:\n",
        "  # Number of bins\n",
        "  num_bins = 10\n",
        "\n",
        "  # Initialize bins for accuracies and confidences\n",
        "  bin_acc = np.zeros(num_bins)\n",
        "  bin_conf = np.zeros(num_bins)\n",
        "  bin_count = np.zeros(num_bins)\n",
        "\n",
        "  # Assign predictions to bins\n",
        "  for acc, conf in zip(acc_list, conf_list):\n",
        "      bin_index = int(conf * num_bins)  # Assuming confidences are in [0,1)\n",
        "      if bin_index == num_bins:  # Handle the case where conf = 1\n",
        "          bin_index -= 1\n",
        "      bin_acc[bin_index] += acc\n",
        "      bin_conf[bin_index] += conf\n",
        "      bin_count[bin_index] += 1\n",
        "\n",
        "  # Calculate ECE\n",
        "  ece = 0\n",
        "  for i in range(num_bins):\n",
        "      if bin_count[i] > 0:\n",
        "          avg_acc = bin_acc[i] / bin_count[i]\n",
        "          avg_conf = bin_conf[i] / bin_count[i]\n",
        "          ece += np.abs(avg_acc - avg_conf) * (bin_count[i] / len(conf_list))\n",
        "\n",
        "  print(f\"ECE: {ece}\")\n",
        "  return ece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "z302On3UtSdY",
        "outputId": "71bf6bd4-f119-46e7-f4e5-946544ce74b4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Code to plot the reliability diagram. Pass the acc_list and conf_list for all strategies to get the reliability diagram\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_reliability(acc_list, conf_list):\n",
        "  num_bins = 10\n",
        "\n",
        "  # Initialize the bins\n",
        "  bin_acc = np.zeros(num_bins)\n",
        "  bin_conf = np.zeros(num_bins)\n",
        "  bin_count = np.zeros(num_bins)\n",
        "\n",
        "  # Assign predictions to bins\n",
        "  for acc, conf in zip(acc_list, conf_list):\n",
        "      bin_index = int(conf * num_bins)  # Assuming confidences are in [0,1)\n",
        "      if bin_index == num_bins:  # Handle the case where conf = 1\n",
        "          bin_index -= 1\n",
        "      bin_acc[bin_index] += acc\n",
        "      bin_conf[bin_index] += conf\n",
        "      bin_count[bin_index] += 1\n",
        "\n",
        "  # Calculate bin accuracies and average confidences\n",
        "  bin_accuracies = [bin_acc[i] / bin_count[i] if bin_count[i] > 0 else 0 for i in range(num_bins)]\n",
        "  bin_average_confidences = [bin_conf[i] / bin_count[i] if bin_count[i] > 0 else 0 for i in range(num_bins)]\n",
        "  edges = np.linspace(0, 1, num=num_bins+1)\n",
        "\n",
        "  # Initialize the figure and axes\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "  # Plot the ideal line with bars (hatched) for the diagonal in pink color\n",
        "  ax.bar(edges[:-1], edges[:-1], width=np.diff(edges), align='edge', color='pink', edgecolor='black', hatch='/', label='Ideal')\n",
        "\n",
        "  # Overlay the prediction accuracy bars on top of the ideal line\n",
        "  ax.bar(edges[:-1], bin_accuracies, width=np.diff(edges), align='edge', color='blue', edgecolor='black', label='Outputs')\n",
        "\n",
        "  # Draw the diagonal line\n",
        "  ax.plot([0, 1], [0, 1], 'k--', label='Diagonal Line')\n",
        "\n",
        "  # Add labels, title, and legend\n",
        "  ax.set_xlabel('Confidence')\n",
        "  ax.set_ylabel('Accuracy')\n",
        "  ax.set_title('Calibration Reliability Diagram')\n",
        "  ax.legend(loc='best')\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHp4bdeHUP4l"
      },
      "outputs": [],
      "source": [
        "# Calculate ECE score by passing the acc list and conf list\n",
        "calculate_ece(acc_list, conf_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyGmQgK2hzoa"
      },
      "outputs": [],
      "source": [
        "# TODO: Pass respective acc_list and conf_list to plot reliability diagram. A sample is provided above\n",
        "plot_reliability(acc_list, conf_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXeXjjyLY5dv"
      },
      "source": [
        "Greedy decoding (setting with temperature $T=0$) can be considered the most naive decoding strategy, where an LM is given a prompt with or without in-context examples and an output is generated. However, this limits the creativity of the LM by generating only one greedy sample per input. An extension to the decoding strategy called *self-consistency*, that provides an alternative to simple greedy decoding by generating a variety of outputs (with $T>0$) instead of just following the most likely one.\n",
        "\n",
        "# Self Consistency\n",
        "\n",
        "Self Consistency approach involves sampling a diverse set of reasoning paths\n",
        "instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. [paper](https://arxiv.org/abs/2203.11171)\n",
        "\n",
        "**How can we best elicit a model's confidence from the consistency of multiple generations?**\n",
        "\n",
        "In a simple setting, we can calculate the percentage of answers that agrees with the most-voted answer and calculate calibration over it ([paper](https://arxiv.org/abs/2402.13904)).\n",
        "\n",
        "We can see how multiple generations can affect calibration below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FY6OaiDbSAd"
      },
      "source": [
        "# Question 4:\n",
        "\n",
        "Change the sampling parameters for all four cases (Zero shot and few shot versions of COT and Subquestion Decomposition) above with temperature = 0.7 and number of samples as 10. Regenerate the samples for all cases above and:\n",
        "1.  Calculate the accuracy again based on self-consistency for the generated 10 samples (create a count-based dictionary and take the most voted answer). Does it outperform the greedy decoded samples from above?\n",
        "2. Revise the confidence score by calculating the self-consistency based agreement (number of samples that agree with the most-voted sample).\n",
        "3. Calculate ECE score for all cases and compare it with the previous scores and mention the differences.\n",
        "4. Plot the reliability diagram for all cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePZI1htFodya"
      },
      "outputs": [],
      "source": [
        "# TODO: write your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFWX8nO_y-In"
      },
      "outputs": [],
      "source": [
        "# TODO: write a function that finds the most common value in a list and returns its count (self consistency)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def find_most_voted_and_indexes(sample_list):\n",
        "    # Count the occurrences of each number\n",
        "    # Find the most common number and its count\n",
        "    most_voted, most_voted_count = 0, 0\n",
        "\n",
        "    return most_voted, most_voted_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_2Oh6mojLBp"
      },
      "outputs": [],
      "source": [
        "# TODO: Calculate accuracy\n",
        "\n",
        "def calculate_accuracy (prompt_style):\n",
        "  acc_list, conf_list = [], []\n",
        "  for test_sample in test_set:\n",
        "    input_to_llm = prompt_style + test_sample[\"question\"]\n",
        "    test_sample_output, all_pred_vals = generate(llm, input_to_llm, 10, 0.7)\n",
        "    # get predictions\n",
        "    # calculate most voted sample and count from function above\n",
        "    acc = 0\n",
        "    acc_list.append(acc)\n",
        "    conf = 0\n",
        "    conf_list.append(conf)\n",
        "    return acc_list, conf_list\n",
        "acc_list, conf_list = calculate_accuracy(prompt_style = \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifVKwZcnuyin",
        "outputId": "5c84020e-8849-4378-aade-46e7679f3b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECE: 0.42000000000000004\n"
          ]
        }
      ],
      "source": [
        "# TODO: calculate ECE score\n",
        "ece_score = calculate_ece(acc_list, conf_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK6o2FO9ohyK"
      },
      "outputs": [],
      "source": [
        "# TODO: plot reliability diagram\n",
        "plot_reliability(acc_list, conf_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IREi0vHZkSbc"
      },
      "source": [
        "# Question 5:\n",
        "\n",
        "Based on all the experiments in the previous questions, answer the following questions as *True* or *False*:\n",
        "1. Explanation-based prompting strategies lead to better calibration?\n",
        "2. Few-shot prompting strategies are more calibrated than zero-shot strategies?\n",
        "3. Self-consistency helps with calibration?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm8bfmaokfDF"
      },
      "source": [
        "TODO: Answer here"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0248df9db9534a7a98d49e11fcb24ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "028bb0fbfdc140dc87d103a438be30d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02c816c5001049d49205088e6038913d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0e11b9d72443d2bf9def227ed2ea63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f0a5e9e57b2466295b7cb1c7a26b0fe",
            "placeholder": "​",
            "style": "IPY_MODEL_a824806e99f4452eb70c34d3c9b6e611",
            "value": " 7.94k/7.94k [00:00&lt;00:00, 532kB/s]"
          }
        },
        "0e038056823240b9835e3d8bdec7ea1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "126d1790bcea40478871169940597201": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "181fdf8a346a490aa6eabbdb0907ef58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f0a5e9e57b2466295b7cb1c7a26b0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200486cf53214f7ea528a5e8718da8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2288d8d0e58d438ea4e69a941469a20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ade627615fc745f6852649b91f06731d",
            "placeholder": "​",
            "style": "IPY_MODEL_6fe8e8e3e86f466a889320d0f081bcb0",
            "value": "Downloading data: 100%"
          }
        },
        "29eaa09b31e34fa19f90f1c578a7cd47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4c1c69632547e58cdb679a56ea2ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6be99ad92e41deba2545c41a5346c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62b9245851b141f79a66281ac9da797b",
              "IPY_MODEL_e2ff941fab2f4e369b2977c87636fbc1",
              "IPY_MODEL_f712424d53004d8b9af4f0b839bab24e"
            ],
            "layout": "IPY_MODEL_29eaa09b31e34fa19f90f1c578a7cd47"
          }
        },
        "4a259eec653f48288266799298319b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54d57e78ff8b463199c60f153941ec76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56ad38b691014c899b1227d6563be570": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc2f3c24d0da489ca8652ecac12ab2b7",
              "IPY_MODEL_6ae4fda98c6b41fa9f73c3d223f32b3c",
              "IPY_MODEL_93b41ab10b1749daaab08d569ae37832"
            ],
            "layout": "IPY_MODEL_0248df9db9534a7a98d49e11fcb24ce0"
          }
        },
        "572a5aa78add43448dabd41c632bdb9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f06e4940c5848c9abca165ebad783b1",
              "IPY_MODEL_a3f0b5b8b00448a68dd6a3082ad3853f",
              "IPY_MODEL_78ef66e03f114444b41996516e1ed965"
            ],
            "layout": "IPY_MODEL_634565d5d7ad42d1aeef4312adcd3cf0"
          }
        },
        "62b9245851b141f79a66281ac9da797b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9422686d4ea340d2b68731e077785348",
            "placeholder": "​",
            "style": "IPY_MODEL_028bb0fbfdc140dc87d103a438be30d8",
            "value": "Generating test split: 100%"
          }
        },
        "634565d5d7ad42d1aeef4312adcd3cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ae4fda98c6b41fa9f73c3d223f32b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa0edf7a372b475bbb2302f0b6571b75",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_181fdf8a346a490aa6eabbdb0907ef58",
            "value": 7473
          }
        },
        "6fe8e8e3e86f466a889320d0f081bcb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "742dc98251b64833895aedfb0a75dc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2288d8d0e58d438ea4e69a941469a20e",
              "IPY_MODEL_c2f26a48ceb847fe8a2c5b0033d79c95",
              "IPY_MODEL_772fc183e47746c4b588f0db80dfbf2f"
            ],
            "layout": "IPY_MODEL_d630ea51a26941a99e6600719f3d425f"
          }
        },
        "772fc183e47746c4b588f0db80dfbf2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4c1c69632547e58cdb679a56ea2ef2",
            "placeholder": "​",
            "style": "IPY_MODEL_c0b2ae5d6a9f4a43b64039f2476ec9ca",
            "value": " 2.31M/2.31M [00:00&lt;00:00, 5.37MB/s]"
          }
        },
        "78ef66e03f114444b41996516e1ed965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_200486cf53214f7ea528a5e8718da8a3",
            "placeholder": "​",
            "style": "IPY_MODEL_d14e849a162441d4b617b6cfea8f22fb",
            "value": " 419k/419k [00:00&lt;00:00, 3.42MB/s]"
          }
        },
        "7f06e4940c5848c9abca165ebad783b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f820abda66f3408094e7c76d49f5af36",
            "placeholder": "​",
            "style": "IPY_MODEL_f495c8b95c1b4c2e966917fb73891916",
            "value": "Downloading data: 100%"
          }
        },
        "93b41ab10b1749daaab08d569ae37832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f01676a335c04e47a589b15276d24912",
            "placeholder": "​",
            "style": "IPY_MODEL_ba9555f939c84ebdbfe46b2ce2e503b5",
            "value": " 7473/7473 [00:00&lt;00:00, 101075.55 examples/s]"
          }
        },
        "9422686d4ea340d2b68731e077785348": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945fc7b512a04a5c8384c325cc1dbe94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e52cb5138534c9195bcc3e5b3a44b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2fa7fcda19f44729d1915e5cf218073": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f0b5b8b00448a68dd6a3082ad3853f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e038056823240b9835e3d8bdec7ea1d",
            "max": 419088,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e52cb5138534c9195bcc3e5b3a44b76",
            "value": 419088
          }
        },
        "a4da2b93fb964890bd8c60b5589be2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5e3d39313ef428fa19f9aa8a156a77b",
              "IPY_MODEL_eb68c89733bc469b886374c0b2095bb6",
              "IPY_MODEL_0d0e11b9d72443d2bf9def227ed2ea63"
            ],
            "layout": "IPY_MODEL_a2fa7fcda19f44729d1915e5cf218073"
          }
        },
        "a824806e99f4452eb70c34d3c9b6e611": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa0edf7a372b475bbb2302f0b6571b75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade627615fc745f6852649b91f06731d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9555f939c84ebdbfe46b2ce2e503b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc2f3c24d0da489ca8652ecac12ab2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1dea8db8b2e4b38ab0af8a8f8a98653",
            "placeholder": "​",
            "style": "IPY_MODEL_f345ad3e23564e91a5dbf3b048cb13d5",
            "value": "Generating train split: 100%"
          }
        },
        "c0b2ae5d6a9f4a43b64039f2476ec9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1dea8db8b2e4b38ab0af8a8f8a98653": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f26a48ceb847fe8a2c5b0033d79c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_126d1790bcea40478871169940597201",
            "max": 2306545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc62eb5beabb41bba0f34f431125eb05",
            "value": 2306545
          }
        },
        "d14e849a162441d4b617b6cfea8f22fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d630ea51a26941a99e6600719f3d425f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc62eb5beabb41bba0f34f431125eb05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e13c992fb9944c6ea599d2002e1610ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e20b6f66359d46218a6e7b9c41c0f4e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ff941fab2f4e369b2977c87636fbc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e20b6f66359d46218a6e7b9c41c0f4e9",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a259eec653f48288266799298319b9a",
            "value": 1319
          }
        },
        "e5e3d39313ef428fa19f9aa8a156a77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02c816c5001049d49205088e6038913d",
            "placeholder": "​",
            "style": "IPY_MODEL_54d57e78ff8b463199c60f153941ec76",
            "value": "Downloading readme: 100%"
          }
        },
        "eb68c89733bc469b886374c0b2095bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4119fbb2ce0418db954e8c4a0f9cf98",
            "max": 7940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9bf4c0504294ba198f3a14fad39cde1",
            "value": 7940
          }
        },
        "f01676a335c04e47a589b15276d24912": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f345ad3e23564e91a5dbf3b048cb13d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4119fbb2ce0418db954e8c4a0f9cf98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f495c8b95c1b4c2e966917fb73891916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f712424d53004d8b9af4f0b839bab24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13c992fb9944c6ea599d2002e1610ad",
            "placeholder": "​",
            "style": "IPY_MODEL_945fc7b512a04a5c8384c325cc1dbe94",
            "value": " 1319/1319 [00:00&lt;00:00, 46949.84 examples/s]"
          }
        },
        "f820abda66f3408094e7c76d49f5af36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9bf4c0504294ba198f3a14fad39cde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
